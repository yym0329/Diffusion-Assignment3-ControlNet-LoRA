{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from diffusion.controlnet import ControlNetModel\n",
    "from diffusion.pipeline_controlnet import StableDiffusionControlNetPipeline\n",
    "from diffusers import UniPCMultistepScheduler\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"runwayml/stable-diffusion-v1-5\"      # NOTE: set as the base Stable Diffusion model\n",
    "controlnet_path = \"./runs/controlnet_fill50k_lr1e-5_batch8_acc1_epochs3\"           # NOTE: set as the output directory of your ControlNet training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ControlNet\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    controlnet_path, \n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "# Load Stable Diffusion with ControlNet\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    base_model_path, \n",
    "    controlnet=controlnet, \n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    ")\n",
    "# Set scheduler\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Load model to GPU\n",
    "pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load condition for ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_image = load_image(\"./data/test_conditions/4.jpg\")\n",
    "prompt = \"forest green circle with an antique brown background\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "control_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "generator = torch.manual_seed(seed)\n",
    "\n",
    "# Generate image\n",
    "image = pipe(\n",
    "    prompt, \n",
    "    num_inference_steps=20, \n",
    "    generator=generator, \n",
    "    image=control_image\n",
    ").images[0]\n",
    "\n",
    "image.save(\"./output4.png\")\n",
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prompts\n",
    "# {\n",
    "#     \"0\": \"pale golden rod circle with old lace background\",\n",
    "#     \"1\": \"sea green circle with a light cyan background\",\n",
    "#     \"2\": \"deep sky blue circle with a light yellow background\",\n",
    "#     \"3\": \"rosy brown circle with a misty rose background\",\n",
    "#     \"4\": \"forest green circle with an antique brown background\"\n",
    "# }\n",
    "\n",
    "# test conditioning images\n",
    "# task_1_controlnet/data/test_conditions/0.png\n",
    "# task_1_controlnet/data/test_conditions/1.png\n",
    "# task_1_controlnet/data/test_conditions/2.jpg\n",
    "# task_1_controlnet/data/test_conditions/3.jpg\n",
    "# task_1_controlnet/data/test_conditions/4.jpg\n",
    "\n",
    "# generate images\n",
    "# seed = 10\n",
    "# generator = torch.manual_seed(seed)\n",
    "\n",
    "test_prompts = [\n",
    "    # \"pale golden rod circle with old lace background\",\n",
    "    \"sea green circle with a light cyan background\",\n",
    "    \"deep sky blue circle with a light yellow background\",\n",
    "    # \"rosy brown circle with a misty rose background\",\n",
    "    # \"forest green circle with an antique brown background\"\n",
    "]\n",
    "test_conditioning_images = [\n",
    "    # \"./data/test_conditions/0.png\",\n",
    "    \"./data/test_conditions/1.png\",\n",
    "    \"./data/test_conditions/2.jpg\",\n",
    "    # \"./data/test_conditions/3.jpg\",\n",
    "    # \"./data/test_conditions/4.jpg\"\n",
    "]\n",
    "\n",
    "for i, (prompt, conditioning_image) in enumerate(zip(test_prompts, test_conditioning_images)):\n",
    "    control_image = load_image(conditioning_image)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    # control_image.show()\n",
    "    image = pipe(\n",
    "        prompt, \n",
    "        num_inference_steps=20, \n",
    "        generator=generator, \n",
    "        image=control_image\n",
    "    ).images[0]\n",
    "    # image.save(os.path.join(controlnet_path, f\"./output{i}.png\"))\n",
    "    paired_plot = Image.new(\"RGB\", (control_image.width * 2, control_image.height))\n",
    "    paired_plot.paste(control_image, (0, 0))\n",
    "    paired_plot.paste(image, (control_image.width, 0))\n",
    "    paired_plot.save(os.path.join(controlnet_path, f\"./paired_plot{i}.png\"))\n",
    "    paired_plot.show()\n",
    "    image.save(os.path.join(controlnet_path, f\"./output{i}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model and Scheduler for ControlNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"runwayml/stable-diffusion-v1-5\"      # NOTE: set as the base Stable Diffusion model\n",
    "controlnet_path = \"./runs/controlnet_fill50k_50k_lrlinear_2epochs_batch4\"           # NOTE: set as the output directory of your ControlNet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ControlNet\n",
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    controlnet_path, \n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "# Load Stable Diffusion with ControlNet\n",
    "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
    "    base_model_path, \n",
    "    controlnet=controlnet, \n",
    "    torch_dtype=torch.float16,\n",
    "    safety_checker=None,\n",
    ")\n",
    "# Set scheduler\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Load model to GPU\n",
    "pipe.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_images = [\n",
    "    'optional_data/image0.png',\n",
    "    'optional_data/image1.png',\n",
    "    'optional_data/image2.png',\n",
    "    'optional_data/image3.png',\n",
    "    'optional_data/image4.png'\n",
    "]\n",
    "\n",
    "text_prompts = [\n",
    "    \"Cars driving down a ancient roman street\",\n",
    "\"Fancy luxury cars are on the roads\",\n",
    "\"There are people marching on the road\",\n",
    "\"Military truck, tanks are parked on the roads\",\n",
    "\"People are walking in the city of paris\"\n",
    "]\n",
    "\n",
    "seed = 10\n",
    "generator = torch.manual_seed(seed)\n",
    "\n",
    "# image looks like: control image, generated image and below the images, the prompt.\n",
    "\n",
    "for i, (prompt, conditioning_image) in enumerate(zip(text_prompts, control_images)):\n",
    "    control_image = load_image(conditioning_image)\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    # control_image.show()\n",
    "    image = pipe(\n",
    "        prompt, \n",
    "        num_inference_steps=20, \n",
    "        generator=generator, \n",
    "        image=control_image\n",
    "    ).images[0]\n",
    "    # image.save(os.path.join(controlnet_path, f\"./output{i}.png\"))\n",
    "    paired_plot = Image.new(\"RGB\", (control_image.width * 2, control_image.height))\n",
    "    paired_plot.paste(control_image, (0, 0))\n",
    "    paired_plot.paste(image, (control_image.width, 0))\n",
    "    paired_plot.save(os.path.join(controlnet_path, f\"./optional-paired_plot{i}.png\"))\n",
    "    paired_plot.show()\n",
    "    image.save(os.path.join(controlnet_path, f\"./optional-output{i}.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pa3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
